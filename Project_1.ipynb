{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Project: CSC 790\n",
    "Team: 01\n",
    "Authors: Rafail Islam, Yeboah Dacosta, Shashi Khanal\n",
    "Project: Deep Convolutional Generative Adversarial Network for generating synthetic images of MNIST dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports library\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model, Input\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & preprocess dataset\n",
    "\n",
    "def load_data( buffer_size=60000, batch_size = 64):\n",
    "    \"\"\" This function loads and preprocesses data, then return train dataset\n",
    "    \"\"\"\n",
    "    # load dataset\n",
    "    (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Reshape image into singel channel\n",
    "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "    \n",
    "    # Normalize image\n",
    "    # Normalize the images to [-1, 1]\n",
    "    train_images = (train_images - 127.5) / 127.5 \n",
    "    \n",
    "    # slip data set by batch_size\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n",
    "    \n",
    "    return train_dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Generator Model\n",
    "def build_generator(noise_dim=100):\n",
    "    \"\"\" Builds generator architecture and return the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # input layer sahpe of noise_dim #Gaussian random numbers\n",
    "    inputs = Input(shape=(noise_dim,) )\n",
    "    \n",
    "    dense_l1 = layers.Dense(256*7*7,activation='relu')(inputs) # start with low regulation image 7*7\n",
    "    bn1 = layers.BatchNormalization() (dense_l1)\n",
    "    lkr1 = layers.LeakyReLU()(bn1)\n",
    "    # Reshape output\n",
    "    rh1 = layers.Reshape((7, 7, 256))(lkr1)\n",
    "    \n",
    "    # Gradually upsampling\n",
    "    # Conv2DTranspose layer 1\n",
    "    cdt1 = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same')(rh1)\n",
    "    bn2 = layers.BatchNormalization() (cdt1)\n",
    "    lkr2 = layers.LeakyReLU()(bn2)\n",
    "    # Conv2DTranspose layer 2\n",
    "    cdt2 = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(lkr2)\n",
    "    bn3 = layers.BatchNormalization() (cdt2)\n",
    "    lkr3 = layers.LeakyReLU()(bn3)\n",
    "    \n",
    "    # Conv2DTranspose layer 3\n",
    "    cdt3 = layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(lkr3)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=inputs,outputs= cdt3)\n",
    "    \n",
    "    return model\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_generator(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,212,608\n",
      "Trainable params: 2,187,136\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Discriminator\n",
    "def build_discriminator():\n",
    "    \"\"\"Builds discriminator architecture and returns model\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Input(shape=(28,28,1,))\n",
    "    \n",
    "    convl1 = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(inputs)\n",
    "    lk1 = layers.LeakyReLU()(convl1)\n",
    "    dp1 = layers.Dropout(0.3)(lk1)\n",
    "    \n",
    "    convl2 = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(dp1)\n",
    "    lk2 = layers.LeakyReLU()(convl2)\n",
    "    dp2 = layers.Dropout(0.3)(lk2)\n",
    "\n",
    "\n",
    "    ftl1 = layers.Flatten()(dp2)\n",
    "    outputs = layers.Dense(1)(ftl1)\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis = build_discriminator()\n",
    "dis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def discriminator_loss(real_output, fake_output,cross_entropy):\n",
    "    \"\"\" Calculates loss for discriminator model and returns it\n",
    "    \"\"\"\n",
    "    # Loss for real images\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    # Loss for fake generated images\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output,cross_entropy):\n",
    "    \"\"\" Calculates loss for generator model and returns it\n",
    "    \"\"\"\n",
    "    gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tf.function\n",
    "def train(images,batch_size,noise_dim,generator,discriminator,generator_optimizer,discriminator_optimizer,cross_entropy):\n",
    "    \"\"\" This function takes batch of train images and train and update both of the generator and discriminator model\n",
    "    \"\"\"\n",
    "    # generating random noise \n",
    "    noise_vector = tf.random.normal([batch_size, noise_dim])\n",
    "        \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        # gernerator model generate fake images\n",
    "        gen_imgs = generator(noise_vector, training=True)\n",
    "        \n",
    "        # Discriminator classify real image and fake generated images\n",
    "        real_outputs = discriminator(images, training=True)\n",
    "        fake_outputs = discriminator(gen_imgs, training=True)\n",
    "        \n",
    "        # calculating loss ofr generator and dicriminator\n",
    "        gen_loss = generator_loss(fake_outputs,cross_entropy)\n",
    "        dis_loss = discriminator_loss(real_outputs, fake_outputs,cross_entropy)\n",
    "\n",
    "    # get gradients\n",
    "    gradient_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradient_dis = disc_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(gradient_gen, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradient_dis, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, dis_loss*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images with trained generator model\n",
    "def generate_image(generator,sample_noise_vector,epoch):\n",
    "    \n",
    "    # generate images\n",
    "    gen_imgs = generator(sample_noise_vector, training=False) # training = False to avoid updating weights\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(gen_imgs.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(gen_imgs[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('./Project_1/images/image_at_epoch_{:04d}.png'.format(epoch+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "buffer_size = 60000\n",
    "batch_size = 200\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8,\tGenerator loss 2.88,\tDiscriminator loss: 0.50\n"
     ]
    }
   ],
   "source": [
    "# --- main block\n",
    "generator = build_generator(100)\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "img_label = discriminator(generated_image)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Random sample for generation fake image over the course of training model\n",
    "sample_noise_vector = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "train_dataset = load_data(buffer_size=buffer_size, batch_size=batch_size)\n",
    "\n",
    "hist_gen_loss = []\n",
    "hist_dis_loss = []\n",
    "for epoch in range (EPOCHS):\n",
    "    gen_loss = 0\n",
    "    dis_loss = 0\n",
    "    c = 0\n",
    "    for batch_imgs in train_dataset:\n",
    "        c +=1\n",
    "        loss1, loss2 = train(batch_imgs,batch_size,noise_dim,generator,discriminator, generator_optimizer,discriminator_optimizer,cross_entropy)\n",
    "        \n",
    "        #print(loss1.numpy())\n",
    "        #print(loss2.numpy())\n",
    "        \n",
    "        gen_loss += loss1.numpy()\n",
    "        dis_loss += loss2.numpy()\n",
    "        \n",
    "        # generate few sample synthetic image while traing\n",
    "        # and save it\n",
    "    display.clear_output(wait=True)\n",
    "        #print('Generator loss %.2f,\\tDiscriminator loss: %.2f'%(loss1,loss2))\n",
    "    if epoch % 5 == 0:\n",
    "        generate_image(generator,sample_noise_vector,epoch)\n",
    "    #generate_image(generator,sample_noise_vector,epoch)\n",
    "        \n",
    "    hist_gen_loss.append(gen_loss/c) # average loss per epoch\n",
    "    hist_dis_loss.append(dis_loss/c)\n",
    "        \n",
    "    print('Epoch %d,\\tGenerator loss %.2f,\\tDiscriminator loss: %.2f'%(epoch+1,loss1,loss2))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(EPOCHS),hist_gen_loss,label='Generator loss')\n",
    "plt.plot(range(EPOCHS),hist_dis_loss,label='Discriminator loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Loss-vs-Epoch_DCGAN\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(\"./Project_1/SavedModel/GenModel1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_generator = tf.keras.models.load_model(\"./Project_1/SavedModel/GenModel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_noise_vector = tf.random.normal([10, 100])\n",
    "gen_imgs = saved_generator(sample_noise_vector, training=False) # training = False to avoid updating weights\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for i in range(gen_imgs.shape[0]):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.imshow(gen_imgs[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"gen_image_\"+str(i+1))\n",
    "\n",
    "    plt.savefig('./Project_1/generated images/gen_image_{:05d}.png'.format(i+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
